{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer.six in /opt/conda/lib/python3.6/site-packages (20181108)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.6/site-packages (from pdfminer.six) (3.9.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from pdfminer.six) (1.11.0)\r\n",
      "Requirement already satisfied: sortedcontainers in /opt/conda/lib/python3.6/site-packages (from pdfminer.six) (2.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import os\n",
    "import pickle\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over txt files in directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that gets text in document into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_content={}\n",
    "list_of_txt = glob.glob('essays/*.txt')\n",
    "for this_path in list_of_txt:\n",
    "    with open(this_path,'r') as ftxt:\n",
    "        content=ftxt.readlines()\n",
    "    txt_content[this_path]=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'essays/week1_1.txt': ['Gill Press’s A Very Short History of Data Science provides a summary of how Data Science was recognized as a field by itself, the tools and models that are specific to Data Science and the necessary disciplines it encompasses.\\n',\n",
       "  '\\n',\n",
       "  'Gill Press provides the history of Data Science chronologically by recognizing Tukey as the first person to state that Data Analysis was more Science than Mathematics.\\n',\n",
       "  '\\n',\n",
       "  'Later in 1974, Peter Naur recognized that the field of Data Science is related to other fields. The need for analysis, as Gill Press writes in the article, requires new algorithm models rather than conventional data model.\\n',\n",
       "  '\\n',\n",
       "  'This need naturally would require other fields such as Computer Science, Mathematics, Statistics and Graphic Design (Web Development) sometimes.'],\n",
       " 'essays/week1_380.txt': ['The first ten pages of 50 years of Data Science discusses if \"Data Science\" is really a new science or a sugar covered Statistics, rebranding of Statistics as mentioned in the article. \\n',\n",
       "  '\\n',\n",
       "  'The article indicated how the terms and definitions used for Data Science are very similar to the ones for statistics. The practices, methodologies that statisticians worked on are now presented as if they are the product of Data Science as a “new discipline”. \\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  'The article also refers to recurring “memes\" for data science and criticizes them as follows. \\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  'The Big Data Meme: It indicates that big data cannot be a handled by statistics. It’s claimed that statistics is for small datasets where the big data is for data science. It’s incorrect for a meaningful distinction between the two. In history, there were cases that statistics worked on the “big data” of its time and they developed methods to carry out the challenge. Mathematical statistics researchers have worked for decades to find solutions to handle big datasets.\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  'The Skills Meme: The article criticizes the notion that data science trainees require the skill set to handle big datasets. It says the skills required to perform these tasks are not as big as it is said. In fact, the skills required are not to make a better inference from the data, they are rather how to handle calculations in distributed systems.\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  'The Jobs Meme: The organizations are not sure how to make use of the skill sets that are being taught in Data Science degree programs. It often requires additional training to be useful to the employer. Data Analysis and Statistics however are quite applicable skills and can easily be ported into any organization.\\n',\n",
       "  '\\n',\n",
       "  '\\n',\n",
       "  'Finally, it’s a real science but not for the reasons mentioned above. It’s the science of learning from the data using the scientific technics that statisticians have developed and used. ']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over PDFs in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pdfs = glob.glob('essays/*.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essays/week1_50 years of data science v2.pdf\n",
      "essays/week1_assignment 1 Summary.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_content={}\n",
    "for this_pdf in list_of_pdfs:\n",
    "    print(this_pdf)\n",
    "    !pdf2txt.py \"$this_pdf\" > file_text.txt\n",
    "    with open('file_text.txt','r') as fil:\n",
    "        fil_content = fil.read()\n",
    "    pdf_content[this_pdf]=fil_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over .docx files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_docx(document):\n",
    "    indx=0\n",
    "    text_in_dict={}\n",
    "    for para in document.paragraphs:\n",
    "        if (len(para.text)>0):\n",
    "            indx+=1\n",
    "            text_in_dict[indx]=para.text\n",
    "    return text_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"essays\"\n",
    "docx_content={}\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".docx\") or filename.endswith(\".doc\"): \n",
    "        this_path=os.path.join(directory, filename)\n",
    "        document = Document(this_path)\n",
    "        docx_content[this_path]=get_text_from_docx(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validate the variable contains what we intended"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for file_path,content in docx_content.items():\n",
    "    print(\"\\n\")\n",
    "    print(file_path)\n",
    "    for paragraph_indx,paragraph_content in content.items():\n",
    "        print(paragraph_indx)\n",
    "        print(paragraph_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consolidate PDF, docx, and txt to a single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents={}\n",
    "\n",
    "for file_path,content in txt_content.items():\n",
    "    doc_string=\"\"\n",
    "    for this_line in content:\n",
    "        doc_string+=this_line\n",
    "        doc_string+=\" \"\n",
    "    all_documents[file_path]=doc_string\n",
    "\n",
    "for file_path,content in docx_content.items():\n",
    "    doc_string=\"\"\n",
    "    for paragraph_indx,paragraph_content in content.items():\n",
    "        doc_string+=paragraph_content\n",
    "        doc_string+=\" \"\n",
    "    all_documents[file_path]=doc_string\n",
    "        \n",
    "for file_path,content in pdf_content.items():\n",
    "    doc_string=\"\"\n",
    "    for this_line in content:\n",
    "        doc_string+=this_line\n",
    "        doc_string+=\" \"\n",
    "    all_documents[file_path]=doc_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verify the content is what we are seeking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['essays/week1_1.txt', 'essays/week1_380.txt', 'essays/week1_summary.docx', 'essays/week2_Summary Week 2.docx', 'essays/week1_Data Wrangling Chap 2.docx', 'essays/week2_summary-Data Wrangling with Python  ch2 p17 to 40.docx', 'essays/week2_Week 2 - Summary of DATA WRANGLING WITH PYTHON Chapter 2.docx', 'essays/week2_Data Wrangling with Python page 17 to 40.docx', 'essays/week1_a Very Short History Of Data Science_1.docx', 'essays/week2_Lists and Dictionaries Summary.docx', 'essays/week2_Data601-Reading Assignment_2.docx', 'essays/week1_a History of Data Science.docx', 'essays/week1_Assignment1.docx', 'essays/week1_reading Summary.docx', 'essays/week1_A Very Short History Of Data Science.docx', 'essays/week1_Data 601- Summary of The History of Data Science .docx', 'essays/week1_50 Years Data Science Summary.docx', 'essays/week2_Summary on Chapter 2 of Data Wrangling in Python.docx', 'essays/week2_Week 2 Reading Summary.docx', 'essays/Week2_summary.docx', 'essays/week1_summary-50 years of data science.docx', 'essays/week1_ Summary.docx', 'essays/week2 summary .docx', 'essays/week1_50 years of data science v2.pdf', 'essays/week1_assignment 1 Summary.pdf'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very short history of Data Science In the article A Very Short History of Data Science, author Gil Press gives an overview of how data scientist became the most sought-after profession. But making sense of data has a long history and has been discussed by scientists, statisticians, librarians, computer scientists, and others for years.  John W. Tukey published The Future of Data Analysis in 1962 and in his paper, he emphasized the idea that Data Analysis has more characteristics of science than that of mathematics. In 1974 Peter Naur defined Data Science as the science of dealing with data and establishing the relation of the data to other fields and sciences. With the mission to link traditional statistical methodology and computer technology to convert data into information and knowledge The International Association for Statistical Computing (IASC) was formed in 1977.  During 1980-1995 many conferences were held, and associations started to focus on the data science and analysis. The 90s saw the rise in the use of data for marketing purpose. Knowledge Discovery in Databases refers to the overall process of discovering useful knowledge from data. The KDD process has other steps such as data mining, data preparation, data selection, data cleaning, incorporation of appropriate prior knowledge, and proper interpretation of the results of mining. The article details the various conferences and paper that detail the evolution of data science from statistics. The various papers published during 1996-2001 focus on the database and using the data available to find a pattern and information that would help business. Data Science Journal and Journal of Data Science was launched in 2002 and 2003 respectively to provide a platform for data workers. A report was published to examine the career development of data scientist. In the year 2009 people started discussing the relevance of data scientists. Companies started looking for data specialist, someone who can extract, visualize, interpret and communicate the data. LinkedIn and Facebook created data scientists group.  Drew Conway presented a data science Venn Diagram- hacking skills, math and statistics knowledge, and substantive expertise. The paper also shows the exponential growth rate in the field of data science and an increase in the data scientist jobs. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents['essays/week1_Assignment1.docx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the dictionary to a serialized file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_documents, open( \"all_documents.pkl\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
